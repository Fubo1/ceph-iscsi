#!/usr/bin/python -u
# NB the python environment is using unbuffered mode (-u), so any "print" statements will appear in the
# syslog 'immediately'

import signal
import logging
import logging.handlers
import netifaces
import subprocess
import time
import sys
import os
import threading
import ssl
from OpenSSL import SSL
from rpm import labelCompare

import ceph_iscsi_config.settings as settings

from ceph_iscsi_config.gateway import GWTarget
from ceph_iscsi_config.lun import LUN
from ceph_iscsi_config.client import GWClient
from ceph_iscsi_config.common import Config
from ceph_iscsi_config.lio import LIO, Gateway
from ceph_iscsi_config.utils import (get_ip, this_host, ipv4_addresses,
                                     gen_file_hash, valid_rpm,
                                     ConfFile)

from rtslib_fb import root
from rtslib_fb.utils import RTSLibError, normalize_wwn

# requires - python-flask-restful
# flask is in RHEL7 repos
from flask import Flask, jsonify, make_response, request, abort

# flask_restful is NOT! Install with pip from EPEL
# (i.e. yum install python-pip && pip install flask-restful)
from flask_restful import Resource, Api

import rados

from functools import wraps

def requires_basic_auth(f):
    @wraps(f)
    def decorated(*args, **kwargs):

        # check credentials supplied in the http request are valid
        auth = request.authorization
        if not auth:
            abort(401)

        if (auth.username != settings.config.api_user or
           auth.password != settings.config.api_password):
            abort(401)

        return f(*args, **kwargs)

    return decorated

def requires_restricted_auth(f):
    @wraps(f)
    def decorated(*args, **kwargs):

        # First check that the source of the request is actually valid
        local_gw = ['127.0.0.1']
        gw_names = [gw for gw in config.config['gateways']
                    if isinstance(config.config['gateways'][gw], dict)]
        gw_ips = [get_ip(gw_name) for gw_name in gw_names] + \
                  local_gw + settings.config.trusted_ip_list

        if request.remote_addr not in gw_ips:
            abort(403)

        # check credentials supplied in the http request are valid
        auth = request.authorization
        if not auth:
            abort(401)

        if (auth.username != settings.config.api_user or
           auth.password != settings.config.api_password):
            abort(401)

        return f(*args, **kwargs)

    return decorated


class APISysInfo(Resource):

    @requires_basic_auth
    def get(self, query_type):

        if query_type == 'ipv4_addresses':

            return make_response(jsonify(data=ipv4_addresses()), 200)

        elif query_type == 'checkconf':

            local_hash = gen_file_hash('/etc/ceph/iscsi-gateway.conf')
            return make_response(jsonify(data=local_hash), 200)

        elif query_type == 'checkversions':

            config_errors = pre_reqs_errors()
            if config_errors:
                return make_response(jsonify(data=config_errors), 500)
            else:
                return make_response(jsonify(data='checks passed'), 200)

        else:
            # Request Unknown
            abort(404,
                  "Unknown query")


class APITarget(Resource):

    @requires_restricted_auth
    def put(self, target_iqn):

        gateway_ip_list = []

        target = GWTarget(logger,
                          str(target_iqn),
                          gateway_ip_list)

        if target.error:
            logger.error("Unable to create an instance of the GWTarget class")
            abort(418,
                  "GWTarget problem - {}".format(target.error_msg))

        target.manage('init')
        if target.error:
            logger.error("Failure during gateway 'init' processing")
            abort(418,
                  "iscsi target 'init' process failed for {} - "
                  "{}".format(target_iqn, target.error_msg))

        return make_response(jsonify(
                             {"message": "Target defined successfully"}), 200)


class APIGatewayConfig(Resource):

    @requires_restricted_auth
    def get(self):

        return make_response(jsonify(config.config), 200)


class APIGateways(Resource):
    @requires_restricted_auth
    def get(self):
        return make_response(jsonify(config.config['gateways']), 200)


class APIGateway(Resource):
    @requires_restricted_auth
    def get(self, gateway_name):

        if gateway_name in config.config['gateways']:

            return make_response(jsonify(
                                 config.config['gateways'][gateway_name]), 200)
        else:
            abort(404,
                  "this isn't the droid you're looking for")

    @requires_restricted_auth
    def put(self, gateway_name):

        # the parameters need to be cast to str for compatibility
        # with the comparison logic in common.config.add_item
        gateway_ips = str(request.form['gateway_ip_list'])
        target_iqn = str(request.form['target_iqn'])
        target_mode = str(request.form.get('mode', 'target'))

        gateway_ip_list = gateway_ips.split(',')

        gateway = GWTarget(logger,
                           target_iqn,
                           gateway_ip_list)

        if gateway.error:
            logger.error("Unable to create an instance of the GWTarget class")
            abort(418,
                  "Error initialising an instance of GWTarget "
                  "for {}: {}".format(gateway_name,
                                      gateway.error_msg))

        gateway.manage(target_mode)
        if gateway.error:
            logger.error("manage({}) logic failed for {}".format(target_mode,
                                                                 gateway_name))
            abort(418,
                  "Error defining the {} gateway: "
                  "{}".format(gateway_name,
                              gateway.error_msg))

        logger.info("created the gateway")

        if target_mode == 'target':
            # refresh only for target definitions, since that's when the config
            # will actually change
            logger.info("refreshing the configuration after the gateway "
                        "creation")
            config.refresh()

        return make_response(jsonify(
                             {"message": "Gateway defined/mapped"}), 200)

    @requires_restricted_auth
    def delete(self, gateway_name):

        gateway = GWTarget(logger,
                           config.config['gateways']['iqn'],
                           '')
        if gateway.error:
            abort(418,
                  "Unable to create an instance of GWTarget")

        gateway.manage('clearconfig')
        if gateway.error:
            abort(400,
                  gateway.error_msg)
        else:

            config.refresh()

            return make_response(jsonify(
                {"message": "Gateway removed successfully"}), 200)


class APIDisks(Resource):
    @requires_restricted_auth
    def get(self):
        # if valid_request(request.remote_addr):
        disk_names = config.config['disks'].keys()
        response = {"disks": disk_names}

        return make_response(jsonify(response), 200)



class APIDisk(Resource):

    @requires_restricted_auth
    def delete(self, image_id):

        # let's assume that the request has been validated by the caller

        # if valid_request(request.remote_addr):
        purge_host = request.form['purge_host']

        pool, image = image_id.split('.', 1)

        lun = LUN(logger,
                  pool,
                  image,
                  '0G',
                  purge_host)

        if lun.error:
            # problem defining the LUN instance
            abort(500,
                  "Error initialising the LUN ({})".format(lun.error_msg))

        lun.remove_lun()
        if lun.error:
            if 'allocated to' in lun.error_msg:
                # attempted to remove rbd that is still allocated to a client
                status_code = 400
            else:
                status_code = 500

            abort(status_code,
                  "Error removing the LUN ({})".format(lun.error_msg))

        config.refresh()

        return make_response(jsonify(
                             {"message": "LUN removed".format(lun.error_msg)}), 200)

    @requires_restricted_auth
    def get(self, image_id):


        if image_id in config.config['disks']:
            return make_response(jsonify(config.config["disks"][image_id]), 200)
        else:
            abort(404,
                  "rbd image {} not found in the configuration".format(image_id))


    @requires_restricted_auth
    def put(self, image_id):
        # A put is for either a create or a resize
        # put('http://127.0.0.1:5000/api/disk/rbd.ansible3',data={'pool': 'rbd','size': '3G','owner':'ceph-1'})

        # FIXME - MUST have a gateway before luns can be created
        # the gateway must exist, since the workflow for mapping a lun will
        # map the lun to TPG's and perform alua setup

        # if valid_request(request.remote_addr):

        rqst_fields = set(request.form.keys())
        if rqst_fields.issuperset(("pool", "size", "owner", "mode")):

            image_name = str(image_id.split('.', 1)[1])
            lun = LUN(logger,
                      str(request.form['pool']),
                      image_name,
                      str(request.form['size']),
                      str(request.form['owner']))
            if lun.error:
                logger.error("Unable to create a LUN instance")
                abort(418, lun.error_msg)

            lun.allocate()
            if lun.error:
                logger.error("LUN allocation problem - {}".format(lun.error_msg))
                abort(418,
                      lun.error_msg)


            if request.form['mode'] == 'create':
                # new disk is allocated, so refresh the local config object
                config.refresh()

                iqn = config.config['gateways']['iqn']
                ip_list = config.config['gateways']['ip_list']

                # Add the mapping for the lun to ensure the block device is
                # present on all TPG's
                gateway = GWTarget(logger,
                                   iqn,
                                   ip_list)

                gateway.manage('map')
                if gateway.error:
                    abort(418,
                          "LUN mapping failed - {}".format(gateway.error_msg))

                return make_response(jsonify({"message": "LUN created"}), 200)

            elif request.form['mode'] == 'resize':

                return make_response(jsonify(
                                     {"message": "LUN resized"}), 200)

        else:

            # this is an invalid request
            abort(400,
                  "Invalid Request - need to provide pool, size and owner")


class APIClients(Resource):
    @requires_restricted_auth
    def get(self):
        # if valid_request(request.remote_addr):
        client_list = config.config['clients'].keys()
        response = {"clients": client_list}

        return make_response(jsonify(response), 200)


class APIClientHandler(Resource):
    def update(self, client_iqn, images, chap, committing_host):

        # convert the comma separated image_list string into a list for GWClient
        if images:
            image_list = str(images).split(',')
        else:
            image_list = []

        client = GWClient(logger, client_iqn, image_list, chap)

        if client.error:
            return 500, "GWClient create failed : {}".format(client.error_msg)

        client.manage('present', committer=committing_host)
        if client.error:
            return 500, "Client update failed: {}".format(client.error_msg)
        else:
            config.refresh()
            return 200, "Client configured successfully"


class APIClientAuth(APIClientHandler):
    @requires_restricted_auth
    def get(self, client_iqn):

        abort(403)


    @requires_restricted_auth
    def put(self, client_iqn):
        """
        Handle auth request
        """

        image_list = request.form['image_list']
        chap = request.form['chap']
        committing_host = request.form['committing_host']

        status_code, status_text = self.update(client_iqn,
                                               image_list,
                                               chap,
                                               committing_host)

        return make_response(jsonify({"message": status_text}), status_code)

    @requires_restricted_auth
    def delete(self, client_iqn):
        abort(405)


class APIClientLUN(APIClientHandler):

    @requires_restricted_auth
    def get(self, client_iqn):
        """
        return the LUNs allocated to this client, straight from the config
        object
        """

        disk = request.form['disk']
        if client_iqn in config.config['clients']:
            lun_config = config.config['clients'][client_iqn]['luns']

            return make_response(jsonify({"message": lun_config}), 200)
        else:
            abort(404, "client does not exist")

    @requires_restricted_auth
    def put(self, client_iqn):
        """
        handle the addition or removal of a lun for a given client
        the image_list provided is used by the GWClient code to determine the
        action to take rather than any specific logic here
        """

        # convert the comma separated image_list string into a list for GWClient
        image_list = request.form['image_list']

        chap = request.form['chap']
        committing_host = request.form['committing_host']

        status_code, status_text = self.update(client_iqn,
                                               image_list,
                                               chap,
                                               committing_host)

        return make_response(jsonify({"message": status_text}), status_code)


class APIClient(APIClientHandler):
    '''
    Handle the definition of a client to the local LIO instance
    '''

    @requires_restricted_auth
    def get(self, client_iqn):

        if client_iqn in config.config['clients']:
            return make_response(jsonify(
                                 config.config["clients"][client_iqn]), 200)
        else:
            abort(404,
                  "Client '{}' does not exist".format(client_iqn))

    @requires_restricted_auth
    def put(self, client_iqn):
        """
        The put request needs the client_iqn as a minimum to get
        the client defined. However, image_list and chap can also
        be provided to define the client fully in one pass
        """

        try:
            valid_iqn = normalize_wwn(['iqn'], client_iqn)
        except RTSLibError:
            abort(400,
                  "'{}' is not a valid name for iSCSI".format(client_iqn))

        committing_host = request.form['committing_host']

        image_list = request.form.get('image_list', '')

        chap = request.form.get('chap', '')

        status_code, status_text = self.update(client_iqn,
                                               image_list,
                                               chap,
                                               committing_host)

        return make_response(jsonify({"message": status_text}), status_code)

    @requires_restricted_auth
    def delete(self, client_iqn):

        committing_host = request.form['committing_host']

        # Make sure the delete request is for a client we have defined
        if client_iqn in config.config['clients'].keys():
            client = GWClient(logger, client_iqn, '', '')
            client.manage('absent', committer=committing_host)

            if client.error:

                abort(500,
                      client.error_msg)

            else:
                if committing_host == this_host():
                    config.refresh()

                return make_response(jsonify(
                                     {"message": "client deleted"}), 200)
        else:
            abort(405,
                  "Invalid Request - client does not exist")


def pre_reqs_errors():
    """
    function to check pre-req rpms are installed and at the relevant versions
    and also check that multipath.conf and lvm.conf have the required
    changes applied
    :return: list of configuration errors detected
    """

    required_rpms = [
        {"name": "device-mapper-multipath",
         "version": "0.4.9",
         "release": "99.el7"},
        {"name": "python-rtslib",
         "version": "2.1.fb57",
         "release": "5.el7"}
    ]

    k_vers = '3.10.0'
    k_rel = '503.el7'

    errors_found = []
    # first check rpm versions are OK
    for rpm in required_rpms:
        if not valid_rpm(rpm):
            logger.error("RPM check for {} failed")
            errors_found.append("{} rpm must be installed at >= "
                                "{}-{}".format(rpm['name'],
                                              rpm['version'],
                                              rpm['release']))


    # check the running kernel is OK (required kernel has patches to rbd.ko)
    os_info = os.uname()
    this_arch = os_info[-1]
    this_kernel = os_info[2].replace(".{}".format(this_arch), '')
    this_ver, this_rel = this_kernel.split('-')

    # use labelCompare from the rpm module to handle the comparison
    if labelCompare(('1', this_ver, this_rel), ('1', k_vers, k_rel)) < 0:
        logger.error("Kernel version check failed")
        errors_found.append("Kernel version too old - {}-{} "
                            "or above needed".format(k_vers,
                                                     k_rel))

    # now check configuration files have the right settings in place
    conf = ConfFile('/etc/multipath.conf')
    if conf.defaults.skip_kpartx != "yes" or \
          conf.defaults.user_friendly_names != 'no' or \
          conf.defaults.find_multipaths != 'no':
        logger.error("/etc/multipath.conf 'defaults' settings are incorrect")
        errors_found.append('multipath.conf defaults section is incorrect')


    conf = ConfFile('/etc/lvm/lvm.conf')
    if conf.devices.global_filter != '[ "r|^/dev/mapper/[0-255]-.*|" ]':
        logger.error("/etc/lvm/lvm.conf global_filter is missing/invalid")
        errors_found.append('lvm.conf is missing global_filter settings')

    return errors_found


def ceph_rm_blacklist(blacklisted_ip):
    """
    Issue a ceph osd blacklist rm command for a given IP on this host
    :param blacklisted_ip: IP address (str - dotted quad)
    :return: boolean for success of the rm operation
    """

    logger.info("Removing blacklisted entry for this host : "
                "{}".format(blacklisted_ip))

    result = subprocess.check_output("ceph osd blacklist rm {}".
                                     format(blacklisted_ip),
                                     stderr=subprocess.STDOUT, shell=True)
    if "un-blacklisting" in result:
        logger.info("Successfully removed blacklist entry")
        return True
    else:
        logger.critical("blacklist removal failed. Run"
                        " 'ceph osd blacklist rm {}'".format(blacklisted_ip))
        return False


def signal_stop(*args):
    """
    Handler to shutdown the service when systemd sends SIGTERM
    NB - args has to be specified since python will pass two parms into the
    handler by default
    :param args: ignored/unused
    """
    logger.info("rbd-target-gw stop received")

    local_gw = this_host()

    if "gateways" in config.config:
        if local_gw not in config.config["gateways"]:
            logger.info("No gateway configuration to remove on this host "
                        "({})".format(local_gw))
            sys.exit(0)
    else:
        logger.info("Configuration object does not hold any gateway metadata"
                    " - nothing to do")
        sys.exit(0)

    # At this point, we're working with a config object that has an entry for
    # this host

    lio = LIO()
    gw = Gateway(config)

    # This will fail incoming IO, but wait on outstanding IO to
    # complete normally. We rely on the initiator multipath layer
    # to handle retries like a normal path failure.
    gw.drop_target(local_gw)
    if gw.error:
        logger.error("rbd-target-gw failed to remove target objects")

    lio.drop_lun_maps(config, False)
    if lio.error:
        logger.error("rbd-target-gw failed to remove lun objects")
    sys.exit(0)


def signal_reload(*args):
    """
    Handler to invoke an refresh of the config, when systemd issues a SIGHUP
    NB - args has to be specified since python will pass two parms into the
    handler by default
    :param args: unused
    :return: runs the apply_config function
    """
    if not config_loading:
        logger.info("Reloading configuration from rados configuration object")

        config.refresh()
        if config.error:
            halt("Unable to read the configuration object - "
                 "{}".format(config.error_msg))

        apply_config()

    else:
        logger.warning("Admin attempted to reload the config during an active "
                       "reload process - skipped, try later")


def map_rbd(rbd_path):
    """
    Attempt to map a given rbd device to the current system
    :param rbd_path: pool/image name for the rbd device to add to this system
    :return: None or the /dev/rbdX response from the rbd map command
    """

    try:
        cmd = "rbd map {} -o noshare".format(rbd_path)
        map_output = subprocess.check_output(cmd, shell=True)
    except subprocess.CalledProcessError:
        return None
    else:
        return map_output.strip()


def rbd_ready(disk):
    """
    determine whether the given disk is ready for allocation to LIO ...
    i.e. it's mapped and has a device mapper entry
    :param disk: disk record (dict)
    :return: Boolean indicating whether the rbd device is usable
    """

    rbd_path = "{}/{}".format(disk['pool'], disk['image'])
    dm_device = disk['dm_device']
    if os.path.exists(dm_device):
        return True

    # Path doesn't exist, so map it
    map_state = map_rbd(rbd_path)
    if map_state is None:
        logger.error("Unable to map {}".format(rbd_path))
        return False

    # return the dm state using the 'wait' function
    return LUN.dm_wait_for_device(dm_device)


def osd_blacklist_cleanup():
    """
    Process the osd's to see if there are any blacklist entries for this node
    :return: True, blacklist entries removed OK, False - problems removing
    a blacklist
    """

    logger.info("Processing osd blacklist entries for this node")

    cleanup_state = True

    try:

        # NB. Need to use the stderr override to catch the output from
        # the command
        blacklist = subprocess.check_output("ceph osd blacklist ls",
                                            shell=True,
                                            stderr=subprocess.STDOUT)

    except subprocess.CalledProcessError:
        logger.critical("Failed to run 'ceph osd blacklist ls'. "
                        "Please resolve manually...")
        cleanup_state = False
    else:

        blacklist_output = blacklist.split('\n')[:-1]
        if len(blacklist_output) > 1:

            # We have entries to look for, so first build a list of ipv4
            # addresses on this node
            ipv4_list = []
            for iface in netifaces.interfaces():
                dev_info = netifaces.ifaddresses(iface).get(netifaces.AF_INET, [])
                ipv4_list += [dev['addr'] for dev in dev_info]

            # process the entries (first entry just says "Listed X entries,
            # last entry is just null)
            for blacklist_entry in blacklist_output[1:]:

                # valid entries to process look like -
                # 192.168.122.101:0/3258528596 2016-09-28 18:23:15.307227
                blacklisted_ip = blacklist_entry.split(':')[0]
                # Look for this hosts ipv4 address in the blacklist

                if blacklisted_ip in ipv4_list:
                    # pass in the ip:port/nonce
                    rm_ok = ceph_rm_blacklist(blacklist_entry.split(' ')[0])
                    if not rm_ok:
                        cleanup_state = False
                        break
        else:
            logger.info("No OSD blacklist entries found")

    return cleanup_state


def halt(message):
    logger.critical(message)
    sys.exit(16)


def get_tpgs():
    """
    determine the number of tpgs in the current LIO environment
    :return: count of the defined tpgs
    """

    return len([tpg.tag for tpg in root.RTSRoot().tpgs])


def apply_config():
    """
    main procesing logic that takes the config object from rados and applies
    it to the local LIO instance using the config module classes (also used by
    the ansible playbooks)
    :return: return code 0 = all is OK, anything
    """

    # access config_loading from the outer scope, for r/w
    global config_loading
    config_loading = True

    local_gw = this_host()

    logger.info("Reading the configuration object to update local LIO "
                "configuration")

    logger.info("Processing Gateway configuration")

    # first check to see if we have any entries to handle - if not, there is
    # no work to do..
    if "gateways" not in config.config:
        logger.info("Configuration is empty - nothing to define to LIO")
        config_loading = False
        return
    if local_gw not in config.config['gateways']:
        logger.info("Configuration does not have an entry for this host({}) - "
                    "nothing to define to LIO".format(local_gw))
        config_loading = False
        return

    # at this point we have a gateway entry that applies to the running host

    gw_ip_list = config.config['gateways']['ip_list'] if 'ip_list' in config.config['gateways'] else None
    gw_iqn = config.config['gateways']['iqn'] if 'iqn' in config.config['gateways'] else None
    gw_nodes = [key for key in config.config['gateways'] if isinstance(config.config['gateways'][key], dict)]

    # Gateway Definition : Handle the creation of the Target/TPG(s) and Portals
    # Although we create the tpgs, we flick the enable_portal flag off so the
    # enabled tpg will not have an outside IP address. This prevents clients
    # from logging in too early, failing and giving up because the nodeACL
    # hasn't been defined yet (yes Windows I'm looking at you!)

    # first check if there are tpgs already in LIO (True) - this would indicate
    # a restart or reload call has been made. If the tpg count is 0, this is a
    # boot time request
    portals_active = get_tpgs() > 0

    gateway = GWTarget(logger,
                       gw_iqn,
                       gw_ip_list,
                       enable_portal=portals_active)

    gateway.manage('target')
    if gateway.error:
        halt("Error creating the iSCSI target (target, TPGs, Portals)")

    logger.info("Processing LUN configuration")

    # LUN management
    # disk_key ... pool.rbd_image
    for disk_key in config.config['disks']:

        disk = config.config['disks'][disk_key]
        dm_path = disk['dm_device']
        if rbd_ready(disk):

            # disk size (4th parameter) is not important here since this
            # is just registration of the devices and disk resize is not
            # supported on boot-up anyway
            lun = LUN(logger, disk['pool'], disk['image'], '0G', local_gw)
            if lun.error:
                halt("Error defining rbd image {}".format(disk_key))

            lun.allocate()
            if lun.error:
                halt("Error unable to register {} with LIO - "
                     "{}".format(disk_key, lun.error_msg))

        else:

            halt("Unable to attach to the dm device {} for "
                 "image {}".format(dm_path, disk_key))

    # Gateway Mapping : Map the LUN's registered to all tpg's within the
    # LIO target
    gateway.manage('map')
    if gateway.error:
        halt("Error mapping the LUNs to the tpg's within the iscsi Target")

    logger.info("Processing client configuration")

    # Client configurations (NodeACL's)
    for client_iqn in config.config['clients']:
        client_metadata = config.config['clients'][client_iqn]
        chap = client_metadata['auth']['chap']
        image_list = client_metadata['luns'].keys()
        client = GWClient(logger, client_iqn, image_list, chap)
        client.manage('present')  # ensure the client exists

    if not portals_active:
        # The tpgs, luns and clients are all defined, but the active tpg
        # doesn't have an IP bound to it yet (due to the enable_portals=False
        # setting above)
        logger.info("Adding the IP to the enabled tpg, allowing iSCSI logins")
        gateway.enable_active_tpg(config)
        if gateway.error:
            halt("Error enabling the IP with the active TPG")

    config_loading = False

    logger.info("iSCSI configuration load complete")


class APIServer(threading.Thread):
    def __init__(self, api_ip='0.0.0.0', api_port=5000, api_debug=True,
                 api_reloader=False):
        threading.Thread.__init__(self)
        self.api_ip = api_ip
        self.api_port = api_port
        self.api_debug = api_debug
        self.api_reloader = api_reloader
        self.app = Flask(__name__)
        api = Api(self.app)

        # MUST set daemon attribute on the thread for a clean shutdown
        self.daemon = True

        api.add_resource(APIGatewayConfig, '/api/config')
        api.add_resource(APIGateways, '/api/gateways')
        api.add_resource(APIGateway, '/api/gateway/<gateway_name>')
        api.add_resource(APIDisks, '/api/disks')
        api.add_resource(APIDisk, '/api/disk/<image_id>')
        api.add_resource(APIClients, '/api/clients')
        api.add_resource(APIClient, '/api/client/<client_iqn>')
        api.add_resource(APIClientAuth, '/api/clientauth/<client_iqn>')
        api.add_resource(APIClientLUN, '/api/clientlun/<client_iqn>')
        api.add_resource(APITarget, '/api/target/<target_iqn>')
        api.add_resource(APISysInfo, '/api/sysinfo/<query_type>')

        log = logging.getLogger('werkzeug')
        log.setLevel(logging.DEBUG)

        # Attach the werkzeug log to the handlers defined in the outer scope
        log.addHandler(file_handler)
        log.addHandler(syslog_handler)

    def run(self):

        if settings.config.api_secure:

            # FIXME - ideally this should be TLSv1_2 !
            context = SSL.Context(SSL.TLSv1_METHOD)

            # Use these self-signed crt and key files
            context.use_privatekey_file('/etc/ceph/iscsi-gateway.key')
            context.use_certificate_file('/etc/ceph/iscsi-gateway.crt')

            # context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)
            # context.load_cert_chain('/etc/ceph/iscsi-gateway.crt',
            # '/etc/ceph/iscsi-gateway.key')
            
        else:
            context = None

        self.app.run(host=self.api_ip,
                     port=self.api_port,
                     debug=self.api_debug,
                     use_reloader=self.api_reloader,
                     ssl_context=context)

class ConfigWatcher(threading.Thread):

    def __init__(self, interval=1):
        threading.Thread.__init__(self)
        self.interval = interval
        self.daemon = True

    def run(self):

        logger.info("Started the configuration watcher thread (checking for"
                    " changes every {}s)".format(self.interval))

        # Every second look at the xattr of the config object
        # if it changes reload the config, so changes implemented on
        # another host are picked up here

        cluster = rados.Rados(conffile=settings.config.cephconf)
        cluster.connect()
        ioctx = cluster.open_ioctx('rbd')
        while True:
            time.sleep(self.interval)

            # look at the internal config object epoch (it could be refreshed
            # within an api call)
            current_epoch = config.config['epoch']

            # get the epoch from the xattr of the config object
            try:
                obj_epoch = int(ioctx.get_xattr('gateway.conf', 'epoch'))
            except rados.ObjectNotFound:
                # daemon is running prior to any config being created or it has
                # skip the error, and
                logger.warning("config object missing, recreating")
                config.refresh()

            else:
                # if it's changed, refresh the local config to ensure a query
                # to this node will return current state
                if obj_epoch != current_epoch:
                    logger.info("Change detected - internal {} / xattr {} "
                                "refreshing".format(current_epoch,
                                                    obj_epoch))
                    config.refresh()


def main():

    config_watcher = ConfigWatcher()
    config_watcher.start()

    # only look for osd blacklist entries when the service starts
    osd_state_ok = osd_blacklist_cleanup()
    if not osd_state_ok:
        sys.exit(16)

    # Read the configuration object and apply to the local LIO instance
    if not config_loading:
        apply_config()

    if settings.config.api_enabled:
        api_thread = APIServer(api_port=settings.config.api_port)
        api_thread.start()


    # Just keep the main process alive to receive SIGHUP/SIGTERM
    while True:
        time.sleep(1)


if __name__ == '__main__':

    # Setup signal handlers for stop and reload actions from systemd
    signal.signal(signal.SIGTERM, signal_stop)
    signal.signal(signal.SIGHUP, signal_reload)

    # setup syslog handler to help diagnostics
    logger = logging.getLogger('rbd-target-gw')
    logger.setLevel(logging.DEBUG)

    # syslog (systemctl/journalctl messages)
    syslog_handler = logging.handlers.SysLogHandler(address='/dev/log')
    syslog_handler.setLevel(logging.INFO)
    syslog_format = logging.Formatter("%(message)s")
    syslog_handler.setFormatter(syslog_format)

    # file target - more verbose logging for diagnostics
    file_handler = logging.FileHandler('/var/log/rbd-target-gw.log', mode='w')
    file_handler.setLevel(logging.DEBUG)
    file_format = logging.Formatter("%(asctime)s [%(levelname)8s] - %(message)s")
    file_handler.setFormatter(file_format)

    logger.addHandler(syslog_handler)
    logger.addHandler(file_handler)

    # config_loading is defined in the outer-scope allowing it to be used as
    # a flag to indicate when the apply_config function is running to prevent
    # multiple reloads from being triggered concurrently
    config_loading = False

    settings.init()

    # config is set in the outer scope, so it's easily accessible to the
    # api classes
    config = Config(logger)
    if config.error:
        halt("Unable to open/read the configuration object")
    else:
        main()
